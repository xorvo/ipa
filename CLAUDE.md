# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

IPA (Intelligent Process Automation) is a pod-based task management system built with Elixir/Phoenix LiveView. The system uses event sourcing and isolated pods to manage autonomous agent-driven tasks.

**Status**: This is a greenfield project. The initial specification exists but implementation has not yet begun.

## Tech Stack

- **Backend**: Elixir/Phoenix with LiveView
- **State Management**: Event Sourcing with custom implementation
- **Persistence**: PostgreSQL with JSON events via Ecto
- **Agent Runtime**: Elixir Claude Code SDK (https://hexdocs.pm/claude_code/readme.html)
- **Concurrency**: Elixir supervision trees
- **Version Control**: Git (repo: git@github.com:xorvo/ipa.git)

## Core Architecture

### Task & Pod (1:1 Relationship)
Each **task** creates exactly one **primary pod**. The pod is an isolated Elixir supervisor tree that contains all components needed to manage the task lifecycle. While future versions may support child pods, the current design limits nesting to maintain system clarity and prevent excessive complexity.

### Workstreams (Parallel Work Layer)
Once a pod starts and generates the initial spec, the **Pod Scheduler** breaks the task into multiple **workstreams** that can be worked on in parallel:

- **One agent per workstream**: Each workstream is assigned to a single agent
- **Dynamic creation**: Workstreams can be created as work progresses, not just at the start
- **Dependency management**: Workstreams can depend on each other (explicitly documented in specs)
- **Concurrency control**: Pod-level max concurrency limits prevent resource exhaustion
- **Event-sourced**: All workstream state is tracked via events in the task's event stream
- **Contextual CLAUDE.md**: Each workstream gets its own generated CLAUDE.md with specific context

Workstreams are the primary mechanism for parallel work execution within a pod.

### Communications (Coordination Layer)
A structured communication system enables **human-agent** and **agent-agent** coordination:

- **Pod-scoped**: All messages are visible within the pod
- **Threaded conversations**: Like Slack, messages can be organized in threads
- **Typed messages**: Question, approval, update, blocker message types
- **Human authority**: Humans have ultimate decision-making power
- **Real-time**: Leverages events and LiveView for instant visibility
- **Inbox/notifications**: Agents and humans get notified of messages needing attention

Communications are first-class citizens in the data model, stored as events and projected into state.

### CLAUDE.md Template System
Multi-level contextual instructions ensure agents have appropriate context:

- **System-level**: Static file with overall IPA architecture and conventions
- **Pod-level**: Static template with task-specific context injected
- **Workstream-level**: Generated by Pod Scheduler with workstream-specific context

Each workspace gets the appropriate CLAUDE.md file injected at creation time.

### Three-Layer Architecture

**Layer 1: Shared Persistence**
- PostgreSQL database for event storage
- Events stored as JSON (JSONB) columns via Ecto
- Single stream per task (workstream events stored in task stream)
- Schema: streams, events, snapshots tables
- Event replay for state reconstruction
- Snapshots for performance optimization

**Layer 2: Pod Infrastructure** (one per active task)
- `Ipa.Pod.Supervisor` - Root supervisor
- `Ipa.Pod.State` - Load/manage state, pod-local pub-sub, workstream tracking
- `Ipa.Pod.Scheduler` - State machine, workstream planning, multi-agent orchestration
- `Ipa.Pod.CommunicationsManager` - Threaded messaging, inbox, approvals
- `Ipa.Pod.WorkspaceManager` - Agent workspace management per workstream
- `Ipa.Pod.ClaudeMdTemplates` - Multi-level CLAUDE.md generation
- `Ipa.Pod.ExternalSync` - JIRA/GitHub synchronization, workstream reporting
- `IpaWeb.Pod.TaskLive` - Real-time task UI (workstreams tab, communications tab)

**Layer 3: Central Management** (singleton)
- `Ipa.CentralManager` - Pod lifecycle management
- `IpaWeb.Dashboard.TasksLive` - Central task listing UI (with workstream counts, message indicators)

### Key Design Patterns

1. **Event Sourcing**: All state changes are immutable events. State is reconstructed by replaying events. Single event stream per task includes all workstream and communication events.

2. **Pod-Local Pub-Sub**: Each pod has internal pub-sub topic `pod:{task_id}:state` for fast local communication between components.

3. **Supervision Trees**: Pods use Elixir's DynamicSupervisor for fault tolerance. Pod crash/restart doesn't affect other tasks.

4. **Workspace Isolation**: Each workstream has its own isolated workspace (`/ipa/workspaces/{task_id}/{workstream_id}`) with contextual CLAUDE.md.

5. **Multi-Agent Coordination**: Workstreams enable parallel work with dependency management and concurrency control. Communications Manager facilitates human-agent and agent-agent coordination.

## Development Workflow

### Spec-Driven Development Process
For each component, follow this sequence:
1. **Spec**: Write detailed component specification in `specs/` folder
2. **Review**: Get spec reviewed and approved
3. **Code**: Implement the component
4. **Test**: Test locally
5. **Review**: Code review
6. **PR**: Create pull request (include specs)
7. **Merge**: After approval

### Git Workflow
- Clone: `git clone git@github.com:xorvo/ipa.git`
- Use `gh` CLI for GitHub operations
- Open PRs when ready for code review
- Include specs in PR description

### Project Organization

- `specs/` - All specification, design, and progress tracking documents
- Top-level status tracker document tracks overall progress `STATUS.md` file
- Each component has dedicated spec folder with detailed description, inputs, outputs, dependencies
- Keep the file structure and workflow clear. Something like this for each component.
  - `specs/{component_name}/spec.md`
  - `specs/{component_name}/tracker.md` to include the todo lists and any details you might want log during your working process. Todo list should include any features, issues.
  - `specs/{component_name}/review.md` - for an agent to review the work based on the spec and point out any issues.


## Development Phases

**Phase 1**: Shared Persistence + Pod Infrastructure (Weeks 1-3)
- PostgreSQL Event Store with JSON events (single stream per task)
- Pod Supervisor basic structure
- Pod State Manager with in-memory projections (workstreams, messages)
- Workspace Manager with CLAUDE.md injection
- CLAUDE.md Template System

**Phase 2**: Pod Communications (Weeks 3-5)
- Communications Manager (threaded messaging, inbox)
- Message types (question, approval, update, blocker)
- Notification system

**Phase 3**: Pod Scheduler (Weeks 5-8) - **Most Complex**
- Workstream planning and breakdown
- Multi-agent orchestration
- Dependency management
- Concurrency control
- State machine logic with workstream support

**Phase 4**: Pod UI + Central Dashboard (Weeks 8-10)
- Pod LiveView with Workstreams Tab
- Pod LiveView with Communications Tab
- Central Dashboard for task listing with workstream counts
- Central Manager for pod lifecycle

**Phase 5**: External Sync (Weeks 10-12)
- ExternalSync JIRA/GitHub connectors
- Workstream progress reporting
- External change detection
- Sync approval gates

**Phase 6**: Polish & Scale (Week 12+)
- Error handling, logging, observability
- State snapshots for faster startup
- Performance tuning for concurrent workstreams

## Common Commands

### Elixir/Phoenix Development

```bash
# Install dependencies
mix deps.get

# Create database (PostgreSQL required)
mix ecto.create

# Run migrations (if using Ecto migrations)
mix ecto.migrate

# Start Phoenix server
mix phx.server

# Run tests
mix test

# Run specific test file
mix test test/path/to/test_file.exs

# Run specific test by line number
mix test test/path/to/test_file.exs:42

# Format code
mix format

# Run dialyzer (type checking)
mix dialyzer

# Interactive Elixir shell with app loaded
iex -S mix phx.server
```

### Database Operations

```bash
# Query PostgreSQL database directly
PGPASSWORD=postgres psql -h localhost -U postgres -d ipa_dev

# Inspect events for a task
PGPASSWORD=postgres psql -h localhost -U postgres -d ipa_dev -c "SELECT * FROM events WHERE stream_id = 'task-uuid';"

# Count events
PGPASSWORD=postgres psql -h localhost -U postgres -d ipa_dev -c "SELECT COUNT(*) FROM events;"

# Backup database
pg_dump -h localhost -U postgres ipa_dev > ipa_backup_$(date +%Y%m%d).sql
```

## Key Interfaces & Modules

### Pod Lifecycle
```elixir
# Start a pod
Ipa.CentralManager.start_pod(task_id)

# Stop a pod
Ipa.CentralManager.stop_pod(task_id)

# Get active pods
Ipa.CentralManager.get_active_pods()
```

### Pod State Management
```elixir
# Append event to event store (single stream for task)
Ipa.Pod.State.append_event(
  task_id,
  :workstream_created,
  %{workstream_id: "ws-1", spec: "...", dependencies: []},
  expected_version  # For optimistic concurrency
)
# Returns: {:ok, new_version} | {:error, :version_conflict}

# Query current state (reconstructed from events)
{:ok, state} = Ipa.Pod.State.get_state(task_id)
# Returns: %{
#   phase: :executing,
#   workstreams: %{"ws-1" => %{...}},
#   messages: [...],
#   agents: [...],
#   ...
# }

# Get workstream state
{:ok, workstream} = Ipa.Pod.State.get_workstream(task_id, workstream_id)

# Get messages
{:ok, messages} = Ipa.Pod.State.get_messages(task_id, thread_id \\ nil)

# Direct event store operations (generic stream API)
Ipa.EventStore.append(task_id, event_type, event_data, actor_id: actor_id)
Ipa.EventStore.read_stream(task_id)
Ipa.EventStore.save_snapshot(task_id, state, version)
```

### Workspace Management
```elixir
# Create workspace for workstream (with CLAUDE.md injection)
Ipa.Pod.WorkspaceManager.create_workspace(
  task_id,
  workstream_id,
  agent_id,
  %{
    repo: "git@github.com:xorvo/ipa.git",
    branch: "main",
    claude_md: generated_claude_md_content
  }
)

# Cleanup workspace
Ipa.Pod.WorkspaceManager.cleanup_workspace(task_id, workstream_id)

# Read file from workspace
Ipa.Pod.WorkspaceManager.read_file(task_id, workstream_id, relative_path)
```

### Communications
```elixir
# Post message
{:ok, message_id} = Ipa.Pod.CommunicationsManager.post_message(
  task_id,
  type: :question,
  content: "Should we proceed with approach A or B?",
  author: "agent-123",
  thread_id: nil
)

# Request approval
{:ok, message_id} = Ipa.Pod.CommunicationsManager.request_approval(
  task_id,
  workstream_id: "ws-1",
  question: "Ready to merge PR?",
  options: ["Yes", "No, needs changes"]
)

# Get inbox
{:ok, inbox} = Ipa.Pod.CommunicationsManager.get_inbox(task_id, unread_only?: true)
```

### Agent Spawning
```elixir
# Spawn agent via Claude Code SDK (in workstream workspace)
{:ok, stream} = ClaudeCode.run_task(
  prompt: workstream_task_prompt,
  cwd: workspace_path,  # Includes workstream-specific CLAUDE.md
  allowed_tools: [:read, :bash],
  stream: true
)
```

## Critical Design Considerations

### Optimistic Concurrency
Use version checking when appending events to detect conflicts:
```elixir
Ipa.Pod.State.append_event(task_id, event_type, data, expected_version)
# Returns {:ok, new_version} | {:error, :version_conflict}
```

### Pod-Local Pub-Sub
Components within a pod communicate via pub-sub topic `pod:{task_id}:state`:
- Scheduler subscribes to react to state changes (workstream completion, approvals)
- CommunicationsManager subscribes to send notifications
- ExternalSync subscribes to push updates
- LiveView subscribes for real-time UI updates

### State Persistence
Pods must flush state to disk before shutdown. On restart, state is reloaded from persisted event store by replaying all events (task, workstreams, messages).

### Workstream Dependencies
Dependencies between workstreams are explicitly tracked in the state. Scheduler monitors completions and unblocks waiting workstreams when dependencies are satisfied.

### Single Event Stream per Task
All events (task, workstreams, agents, messages) are stored in a single event stream per task. While concurrent workstream writes may encounter version conflicts, the retry mechanism ensures all events are eventually appended successfully.

## External Integrations

### GitHub
- Create/update PRs
- Fetch PR comments
- Use `gh` CLI for operations

### JIRA
- Update ticket status
- Post comments
- Sync task state to JIRA fields

Both connectors handle:
- Authentication
- Rate limiting
- Retries
- Optional human approval gates

## Testing Strategy

- **Unit Tests**: Individual component logic (state machines, event handling)
- **Integration Tests**: Pod lifecycle, agent spawning, state persistence
- **End-to-End Tests**: Full task flow from creation to completion
- Focus areas: Event replay consistency, version conflicts, pub-sub delivery, workspace isolation

## Event Store Schema

The PostgreSQL database uses a **streams-based** event sourcing model. Streams are generic sequences of events that can represent tasks, agents, or any other aggregate.

### Streams Table
A stream is a sequence of related events (e.g., all events for a task).

```sql
CREATE TABLE streams (
  id VARCHAR(255) PRIMARY KEY,      -- UUID (stream_id)
  stream_type VARCHAR(50) NOT NULL, -- Type: "task", "agent", etc.
  created_at BIGINT NOT NULL,       -- Unix timestamp
  updated_at BIGINT NOT NULL        -- Updated on each event append
);

CREATE INDEX idx_streams_type ON streams(stream_type);
CREATE INDEX idx_streams_updated ON streams(updated_at);
```

**Note**: For tasks, `stream_id` = `task_id`. The stream_type would be "task".

### Events Table
```sql
CREATE TABLE events (
  id BIGSERIAL PRIMARY KEY,
  stream_id VARCHAR(255) NOT NULL,
  event_type VARCHAR(100) NOT NULL, -- e.g., "task_created", "agent_started"
  event_data JSONB NOT NULL,        -- JSON (JSONB for better querying)
  version INTEGER NOT NULL,         -- Incremental per stream
  actor_id VARCHAR(255),            -- Who caused this event
  causation_id VARCHAR(255),        -- Event that caused this event
  correlation_id VARCHAR(255),      -- For tracing related events
  metadata JSONB,                   -- JSON (additional context)
  inserted_at BIGINT NOT NULL,      -- Unix timestamp
  FOREIGN KEY (stream_id) REFERENCES streams(id) ON DELETE CASCADE,
  UNIQUE (stream_id, version)       -- Ensures version uniqueness per stream
);

CREATE INDEX idx_events_stream_id ON events(stream_id);
CREATE INDEX idx_events_version ON events(stream_id, version);
CREATE INDEX idx_events_type ON events(event_type);
CREATE INDEX idx_events_correlation ON events(correlation_id);
CREATE INDEX idx_events_actor ON events(actor_id);
```

### Snapshots Table (Optional - for performance)
```sql
CREATE TABLE snapshots (
  stream_id VARCHAR(255) PRIMARY KEY,
  snapshot_data JSONB NOT NULL,     -- JSON of full state
  version INTEGER NOT NULL,         -- Event version at snapshot
  created_at BIGINT NOT NULL,       -- Unix timestamp
  FOREIGN KEY (stream_id) REFERENCES streams(id) ON DELETE CASCADE
);
```

## References

- PostgreSQL: https://www.postgresql.org/
- Ecto: https://hexdocs.pm/ecto/
- Claude Code SDK: https://hexdocs.pm/claude_code/readme.html
- Phoenix LiveView: https://hexdocs.pm/phoenix_live_view/
- Elixir Supervision: https://hexdocs.pm/elixir/Supervisor.html
